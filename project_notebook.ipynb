{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science final project\n",
    "\n",
    "By: Yehhuda Benais and Tal Tubul"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports:\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup  \n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import os.path\n",
    "import csv\n",
    "import ast\n",
    "import math\n",
    "import statistics as stat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **crawling functions**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The next function handeling the data we get from the functions: \n",
    "```python\n",
    "get_tma() \n",
    "```\n",
    "```python\n",
    "get_Construction_evacuation_complexes()\n",
    "```\n",
    "The function gets a list of addresses and returns:\n",
    "\n",
    "   **case 1:** street's name 23-25 ==> [street's name 23, street's name 24, street's name 25]\n",
    "\n",
    "   **case 2:** street's name 23,24 ==> [street's name 23, street's name 24]\n",
    "\n",
    "   **case 3:** street's name 23 ==> [street's name 23]\n",
    "   \n",
    "   **case 4:** street's name ==> [street's name]\n",
    "\n",
    "The function have been writed with chatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_addresses(addresses):\n",
    "    fixed_addresses = []\n",
    "    for address in addresses:\n",
    "        # remove number between parentheses\n",
    "        address = re.sub(r'\\(\\d+\\)', '', address)\n",
    "        # split address by hyphen\n",
    "        hyphen_split = address.split('-')\n",
    "        for i in range(0, len(hyphen_split)):\n",
    "            hyphen_split[i] = hyphen_split[i].strip()\n",
    "        if len(hyphen_split) == 2:\n",
    "            # check if both sides of hyphen are numbers\n",
    "            if hyphen_split[0][-1].isdigit() and hyphen_split[1].isdigit() or (not hyphen_split[1].isalpha() and not any(c.isalpha() for c in hyphen_split[1])):\n",
    "                start_num = int(re.sub(r'\\D', '', hyphen_split[0]))\n",
    "                end_num = int(re.sub(r'\\D', '', hyphen_split[1]))\n",
    "                # add new addresses to fixed_addresses\n",
    "                for num in range(start_num, end_num + 1):\n",
    "                    fixed_addresses.append(hyphen_split[0].strip('1234567890,-()') + ' ' + str(num))\n",
    "            else:\n",
    "                fixed_addresses.append(address)\n",
    "        else:\n",
    "            # check if address has numbers separated by comma\n",
    "            comma_split = address.split(',')\n",
    "            if len(comma_split) > 1:\n",
    "                addresses = re.split('\\s*,\\s*', address)\n",
    "                fixed_addresses.append(addresses[0])\n",
    "                home = ''.join([char for char in address if char.isalpha() or char.isspace()])\n",
    "                #home = address.strip('1234567890,-()')\n",
    "                addresses.pop(0)\n",
    "                for addr in addresses:   \n",
    "                    fixed_addresses.append(f'{home} {addr}')\n",
    "            else: \n",
    "                fixed_addresses.append(address)    \n",
    "    return fixed_addresses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **tma 38 projects crawlings:**\n",
    "##### the next two functions get the URL of a city \n",
    "##### and return a list with all the adresses that have tma 38 project from the current URL's page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tma(url):\n",
    "# Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    # Parse the HTML content of the response using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    # zFind the table with the specified ID\n",
    "    table = soup.find(\"table\", {\"class\": \"gridView\"})\n",
    "    # Find all the rows in the table and extract the values in the \"כתובת\" column\n",
    "    rows = table.find_all(\"tr\")\n",
    "    addresses_p = []\n",
    "    for row in rows:\n",
    "        cells = row.find_all(\"td\", attrs={\"class\",\"gv_cc\"})\n",
    "        if len(cells) >= 3:\n",
    "            addresses_p.append(cells[1].text)\n",
    "        cells = row.find_all(\"td\", attrs={\"class\",\"gv_cc2\"})\n",
    "        if len(cells) >= 3:\n",
    "            addresses_p.append(cells[1].text)\n",
    "    addresses_p = [s.strip('\\r\\n\\t') for s in addresses_p]\n",
    "    return fix_addresses(addresses_p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The next function gets city name and crawling from the website: tma-38, \n",
    " all the tma-38 projects that are maded and projecets that are now at proccesses at the city. \n",
    " **The function uses the next URL's:**\n",
    " ##### The next URL is to get all the tma 38 progects from type-1 that are currently in proccesses:\n",
    " [\"https://www.t-m-a38.co.il/Default.aspx?gvprojects__gvac=1&gvprojects__gvff0={city}&gvprojects__gvfl0=0&gvprojects__gvpi={i}&tabid=65\"](https://)\n",
    " ##### The next URL is to get all the tma 38 progects from type-2 that are currently in proccesses:\n",
    " [\"https://www.t-m-a38.co.il/Default.aspx?gvprojects__gvac=1&gvprojects__gvff0={city}&gvprojects__gvfl0=0&gvprojects__gvpi={i}&tabid=118\"](https://)\n",
    " ##### The next URL is to get all the tma 38 progects that have been ended thier proccesses:\n",
    " [\"https://www.t-m-a38.co.il/Default.aspx?gvprojects__gvac=1&gvprojects__gvff0={city}&gvprojects__gvfl0=0&gvprojects__gvpi={i}&tabid=96\"](https://)\n",
    "\n",
    " The function return a dict with all the adresses that have tma 38 project with the next values:\n",
    "\n",
    " 1 ==> if the progect is during tma38 process\n",
    "\n",
    " 2 ==> if the progect is during tma38 type 2 process \n",
    " \n",
    " 3 ==> if the progect is ended the tma38 process\n",
    "\n",
    " if the customer entered a wrong value of city the functions will return an empty dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tma_df(city):\n",
    "    unfinished_tma = []\n",
    "    unfinished_tma_type2 = []\n",
    "    finished_tma = []\n",
    "    for i in range(15):\n",
    "        url = f\"https://www.t-m-a38.co.il/Default.aspx?gvprojects__gvac=1&gvprojects__gvff0={city}&gvprojects__gvfl0=0&gvprojects__gvpi={i}&tabid=65\"\n",
    "        unfinished_tma += get_tma(url)\n",
    "        url = f\"https://www.t-m-a38.co.il/Default.aspx?gvprojects__gvac=1&gvprojects__gvff0={city}&gvprojects__gvfl0=0&gvprojects__gvpi={i}&tabid=118\"\n",
    "        unfinished_tma_type2 += get_tma(url)\n",
    "        url = f\"https://www.t-m-a38.co.il/Default.aspx?gvprojects__gvac=1&gvprojects__gvff0={city}&gvprojects__gvfl0=0&gvprojects__gvpi={i}&tabid=96\"\n",
    "        finished_tma += get_tma(url)\n",
    "    string_dict = {s: i for i, strings in enumerate([unfinished_tma, unfinished_tma_type2, finished_tma], start=1) for s in strings}\n",
    "    # Print dictionary\n",
    "    return string_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Construction evacuation projects crawlings:**\n",
    "##### The next function get's city's name and the URL of the goverment's website for Construction evacuation projects\n",
    "##### and return a list with all the adresses that have been part of construction evacuation project at the current city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Construction_evacuation_complexes(city_name):\n",
    "    # Set up the webdriver\n",
    "    driver = webdriver.Chrome()\n",
    "    # Navigate to the job search website\n",
    "    driver.get(\"https://www.gov.il/apps/moch/viewlist/renew/mitchamim-rashut\")\n",
    "    # Wait for the paginator to load\n",
    "    paginator = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"p-paginator\")))\n",
    "    #Find the search/filter input element and enter the city name\n",
    "    time.sleep(1.2)\n",
    "    search_input = driver.find_element(By.CSS_SELECTOR, \"#search\")\n",
    "    search_input.send_keys(city_name)\n",
    "    time.sleep(1)\n",
    "    data = []\n",
    "    # Click all \"Next\" buttons until there is no button left\n",
    "    while True:\n",
    "        next_button = paginator.find_element(By.CSS_SELECTOR, \".ui-paginator-next\")\n",
    "        tbody = None\n",
    "        tbody = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME,\"tbody\")))\n",
    "        try:\n",
    "            time.sleep(1)\n",
    "            temp = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME,\"column-value\")))\n",
    "        except:\n",
    "           print(\"invalid input try again...\") \n",
    "           return []\n",
    "        if tbody:\n",
    "            some = tbody.find_elements(By.CSS_SELECTOR, \"td\")\n",
    "            for value in some:\n",
    "                data.append(value.text)\n",
    "        if \"ui-state-disabled\" in next_button.get_attribute(\"class\"):\n",
    "            # No more next buttons, exit loop\n",
    "            break\n",
    "        next_button.click()  \n",
    "    # Close the webdriver\n",
    "    driver.quit()\n",
    "    for d in range(0, len(data)):\n",
    "        if ('יישוב: ' + city_name) in data[d]:\n",
    "           fixed_data = data[(d+1)::9]\n",
    "           break\n",
    "    return  fix_addresses(fixed_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tabu crawling:**\n",
    "#### The function get the full address of an apartment and return if she have a tabu or not.\n",
    "#### The function uses the next URL for crawling: https://al-harishum.moch.gov.il/\n",
    "##### Due to a blocking system at the current website we coulded crawl the website..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tabu(city, street, number):\n",
    "    strongs = None\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(\"https://al-harishum.moch.gov.il/\")\n",
    "    \n",
    "    # Wait for the inputs to load:\n",
    "    _city = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, \"ctl00_ctl00_ContentPlaceHolder1_ContentPlaceHolder1_SearchPanel_TabContainer1_TabPanelAddress_txtYeshuv\")))\n",
    "    _number = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, \"ctl00_ctl00_ContentPlaceHolder1_ContentPlaceHolder1_SearchPanel_TabContainer1_TabPanelAddress_txtBait\")))\n",
    "    _street = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, \"ctl00_ctl00_ContentPlaceHolder1_ContentPlaceHolder1_SearchPanel_TabContainer1_TabPanelAddress_txtRechov\")))\n",
    "    \n",
    "    # Enter values into the inputs:\n",
    "    _city.send_keys(city)\n",
    "    _number.send_keys(number)\n",
    "    _street.send_keys(street)\n",
    "    \n",
    "    # Click the search button:\n",
    "    button = driver.find_element(By.ID, \"ctl00_ctl00_ContentPlaceHolder1_ContentPlaceHolder1_SearchPanel_TabContainer1_TabPanelAddress_btnAddress\")\n",
    "    button.click()\n",
    "    \n",
    "    # Check if the invalid state element exists:\n",
    "    try:\n",
    "        strongs = driver.find_elements(By.TAG_NAME, \"strong\")\n",
    "        strong = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, \"ctl00_ctl00_ContentPlaceHolder1_ContentPlaceHolder1_NoBotInvalidState\")))\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    driver.quit()\n",
    "    return strongs\n",
    "res = get_tabu('אשדוד', 'הר כנען 2', '2')\n",
    "for r in res:\n",
    "    print(r.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Yad-2 crawling:**\n",
    "##### The function get's the room's number and a URL for a city and return a meta data with all the apartments for sale at the current city with the next properties: \n",
    "prices, streets, cities, floors, sizes, terraces, floors_in_building, parkings, aircondition, bars, elevators, water_headers, accessibility, shelters, renovated, storages, tadiran, furnitures, status, time_enter, sea_view, sukka.\n",
    "##### The function uses the next URLs:\n",
    "**Jerusalem**:https://www.yad2.co.il/realestate/forsale?topArea=100&area=7&city=3000&rooms=3-3\n",
    "\n",
    "**Tel-aviv**: https://www.yad2.co.il/realestate/forsale?topArea=2&area=1&city=5000&rooms=3-3\n",
    "\n",
    "**Haifa**: https://www.yad2.co.il/realestate/forsale?topArea=25&area=5&city=4000&rooms=3-3\n",
    "\n",
    "**Rishon-lezion**: https://www.yad2.co.il/realestate/forsale?topArea=2&area=9&city=8300&rooms=3-3\n",
    "\n",
    "**Petah-tikva**: https://www.yad2.co.il/realestate/forsale?topArea=2&area=4&city=7900&rooms=3-3\n",
    "\n",
    "**Netanya**: https://www.yad2.co.il/realestate/forsale?topArea=19&area=17&city=7400&rooms=3-3\n",
    "\n",
    "**Holon**: https://www.yad2.co.il/realestate/forsale?topArea=2&area=11&city=6600&rooms=3-3\n",
    "\n",
    "**Beer-sheba**: https://www.yad2.co.il/realestate/forsale?topArea=43&area=22&city=9000&rooms=3-3\n",
    "\n",
    "**Bnei-brakh**: https://www.yad2.co.il/realestate/forsale?topArea=2&area=78&city=6100&rooms=3-3\n",
    "\n",
    "**Ashdod**: https://www.yad2.co.il/realestate/forsale?topArea=41&area=21&city=0070&rooms=3-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(rooms):\n",
    "    prices = [] \n",
    "    streets = []\n",
    "    cities = []\n",
    "    floors = [] \n",
    "    sizes = []\n",
    "    terraces = [] \n",
    "    floors_in_building = [] \n",
    "    parkings = []\n",
    "    aircondition = []\n",
    "    bars = [] \n",
    "    elevators = []\n",
    "    water_headers = [] \n",
    "    accessibility = [] \n",
    "    shelters = [] \n",
    "    renovated = []\n",
    "    storages = []\n",
    "    tadiran = []\n",
    "    flexiable = []\n",
    "    furnitures = [] \n",
    "    status = []\n",
    "    time_enter = []\n",
    "    sea_view = []\n",
    "    sukka = []\n",
    "    to_text = []\n",
    "    city = []\n",
    "    driver = webdriver.Edge()\n",
    "    driver.get(f\"https://www.yad2.co.il/realestate/forsale?topArea=100&area=7&city=3000&property=1&rooms={rooms}-{rooms}\")\n",
    "    pages = WebDriverWait(driver, 80).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".page-num\")))\n",
    "    if pages:\n",
    "        for page in range(1,int(pages.pop().text)+1):\n",
    "            driver.get(f\"https://www.yad2.co.il/realestate/forsale?topArea=100&area=7&city=3000&property=1&rooms={rooms}-{rooms}&page={page}\")\n",
    "            pages = WebDriverWait(driver, 80).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".page-num\"))) \n",
    "            index = 0\n",
    "            while index < 39:\n",
    "                try:\n",
    "                    ad_button = driver.find_element(By.ID, 'slot-close-button')\n",
    "                    ad_button.click()\n",
    "                except:\n",
    "                    pass\n",
    "                item = driver.find_element(By.ID, f\"feed_item_{index}\")\n",
    "                try:\n",
    "                    time.sleep(0.8)\n",
    "                    item.click()\n",
    "                    waitt = WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.ID,f'accordion_wide_{index}')))\n",
    "                    time.sleep(1.2)\n",
    "                    try:\n",
    "                        city = item.find_element(By.CLASS_NAME, \"subtitle\").text\n",
    "                        if city:\n",
    "                            cities.append(city)\n",
    "                        else: cities.append('nan')\n",
    "                    except:\n",
    "                        cities.append('nan')\n",
    "                    street = item.find_element(By.ID, f\"feed_item_{index}_title\").text\n",
    "                    if street:\n",
    "                        streets.append(street)\n",
    "                    else: streets.append('nan')\n",
    "                    floor = driver.find_element(By.ID, f\"data_floor_{index}\").text\n",
    "                    if floor:\n",
    "                        floors.append(floor)\n",
    "                    else: floors.append('nan')\n",
    "                    size = driver.find_element(By.ID, f\"data_SquareMeter_{index}\").text\n",
    "                    if size:\n",
    "                        sizes.append(size)\n",
    "                    else: sizes.append('nan')\n",
    "                    price = driver.find_element(By.ID, f\"feed_item_{index}_price\").text\n",
    "                    if price:\n",
    "                        prices.append(price)\n",
    "                    else: prices.append('nan')\n",
    "                    waitt = WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.ID,f'accordion_wide_{index}')))\n",
    "                    data_list = item.find_elements(By.TAG_NAME,'dl')\n",
    "                    if data_list:\n",
    "                        flag = 0\n",
    "                        for d in data_list:\n",
    "                            to_text.append(d.text)\n",
    "                        for t in to_text:\n",
    "                            if 'מצב הנכס' in t:\n",
    "                                status.append(t)\n",
    "                                flag = 1\n",
    "                                break \n",
    "                        if flag == 0:\n",
    "                            status.append('none')\n",
    "                        else: flag = 0\n",
    "                        for t in to_text:\n",
    "                            if 'תאריך כניסה' in t:\n",
    "                                time_enter.append(t)\n",
    "                                flag = 1\n",
    "                                break \n",
    "                        if flag == 0:\n",
    "                            time_enter.append('none')\n",
    "                        else: flag = 0        \n",
    "                        for t in to_text:\n",
    "                            if 'מרפסות' in t:\n",
    "                                terraces.append(t)\n",
    "                                flag = 1\n",
    "                                break \n",
    "                        if flag == 0:\n",
    "                            terraces.append('none')\n",
    "                        else: flag = 0      \n",
    "                        for t in to_text:\n",
    "                            if 'חניות' in t:\n",
    "                                parkings.append(t)\n",
    "                                flag = 1\n",
    "                                break \n",
    "                        if flag == 0:\n",
    "                            parkings.append('none')\n",
    "                        else: flag = 0\n",
    "                        for t in to_text:\n",
    "                            if 'קומות בבנין' in t:\n",
    "                                floors_in_building.append(t)\n",
    "                                flag = 1\n",
    "                                break \n",
    "                        if flag == 0:\n",
    "                            floors_in_building.append('none')\n",
    "                        else: flag = 0\n",
    "                        to_text.clear() \n",
    "                    else:\n",
    "                        status.append('nan')\n",
    "                        parkings.append('nan')\n",
    "                        floors_in_building.append('nan')\n",
    "                        terraces.append('nan')\n",
    "                        time_enter.append('nan')\n",
    "                    contect = item.find_elements(By.CLASS_NAME,\"show-more-container\")\n",
    "                    if contect:\n",
    "                        if ('הים' in contect[0].text or 'לים' in contect[0].text) and 'נוף' in contect[0].text:\n",
    "                            sea_view.append(1)\n",
    "                        else: sea_view.append(0)\n",
    "                        if 'סוכה' in contect[0].text and 'מרפסת' in contect[0].text:\n",
    "                            sukka.append(1)\n",
    "                        else: sukka.append(0)\n",
    "                    else: \n",
    "                        sea_view.append(0)\n",
    "                        sukka.append(0)\n",
    "                    elements2 = item.find_elements(By.CSS_SELECTOR, 'div.items_container > div.info_feature')\n",
    "                    time.sleep(0.5)\n",
    "                    if elements2:\n",
    "                        for element in elements2:\n",
    "                            class_name = element.get_attribute('class')\n",
    "                            if class_name == 'info_feature':\n",
    "                                result = 1\n",
    "                            elif class_name == 'info_feature delete':\n",
    "                                result = 0\n",
    "                            text = element.text\n",
    "                            if 'נכס בבלעדיות' in text or 'מטבח כשר' in text:\n",
    "                                continue\n",
    "                            if 'מיזוג' in text:\n",
    "                                aircondition.append(result)\n",
    "                                continue\n",
    "                            elif 'סורגים' in text:\n",
    "                                bars.append(result)\n",
    "                                continue\n",
    "                            elif 'מעלית' in text:\n",
    "                                elevators.append(result)\n",
    "                                continue\n",
    "                            elif 'דוד שמש' in text:\n",
    "                                water_headers.append(result)\n",
    "                                continue\n",
    "                            elif 'גישה לנכים' in text:\n",
    "                                accessibility.append(result)\n",
    "                                continue\n",
    "                            elif 'ממ\"ד' in text:\n",
    "                                shelters.append(result)\n",
    "                                continue\n",
    "                            elif 'משופצת' in text:\n",
    "                                renovated.append(result)\n",
    "                                continue\n",
    "                            elif 'מחסן' in text:\n",
    "                                storages.append(result)\n",
    "                                continue\n",
    "                            elif 'מזגן תדיראן' in text:\n",
    "                                tadiran.append(result)\n",
    "                                continue\n",
    "                            elif 'ריהוט' in text:\n",
    "                                furnitures.append(result)\n",
    "                                continue\n",
    "                            elif 'גמיש' in text:\n",
    "                                flexiable.append(result)\n",
    "                                continue\n",
    "                    else:\n",
    "                        flexiable.append('nan')  \n",
    "                        furnitures.append('nan') \n",
    "                        tadiran.append('nan') \n",
    "                        renovated.append('nan') \n",
    "                        shelters.append('nan') \n",
    "                        accessibility.append('nan') \n",
    "                        water_headers.append('nan') \n",
    "                        elevators.append('nan') \n",
    "                        bars.append('nan') \n",
    "                        aircondition.append('nan')\n",
    "                        storages.append('nan') \n",
    "                    index += 1\n",
    "                except:\n",
    "                    pass\n",
    "            print(f'{len(streets)} {len(prices)} {len(cities)} {len(sizes)} {len(floors)} {len(furnitures)}  {len(tadiran)} {len(bars)} {len(floors_in_building)} {len(parkings)} {len(sea_view)}')\n",
    "            data = {\n",
    "                'prices': prices,\n",
    "                'streets': streets,\n",
    "                'cities': cities,\n",
    "                'floors': floors,\n",
    "                'sizes': sizes,\n",
    "                'terraces': terraces,\n",
    "                'floors_in_building': floors_in_building,\n",
    "                'parkings': parkings,\n",
    "                'aircondition': aircondition,\n",
    "                'bars': bars,\n",
    "                'elevators': elevators,\n",
    "                'water_headers': water_headers,\n",
    "                'accessibility': accessibility,\n",
    "                'shelters': shelters,\n",
    "                'renovated': renovated,\n",
    "                'storages': storages,\n",
    "                'tadiran': tadiran,\n",
    "                'furnitures': furnitures,\n",
    "                'status': status,\n",
    "                'time_enter': time_enter,\n",
    "                'sea_view': sea_view,\n",
    "                'sukka': sukka\n",
    "            }\n",
    "            df = pd.DataFrame(data)\n",
    "            filename = 'C:\\\\Users\\\\Tal\\\\Desktop\\\\לימודים\\\\מדעי נתונים\\\\jerusalem_df_file_3_rooms.csv'\n",
    "            #write data to the file:\n",
    "            file_exists = os.path.isfile(filename)\n",
    "            with open(filename, 'a', newline='') as csvfile:\n",
    "                fieldnames = ['prices', 'streets', 'cities', 'floors', 'sizes', 'terraces', 'floors_in_building', 'parkings', 'aircondition', 'bars', 'elevators', 'water_headers', 'accessibility', 'shelters', 'renovated', 'storages', 'tadiran', 'furnitures', 'status', 'time_enter', 'sea_view', 'sukka']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                if not file_exists:\n",
    "                    writer.writeheader()\n",
    "                writer.writerow(data)\n",
    "            for l in [prices, streets, cities, floors, sizes, terraces, floors_in_building, parkings, aircondition, bars, elevators, water_headers, accessibility, shelters, renovated, storages, tadiran, furnitures, status, time_enter, sea_view, sukka]:\n",
    "                l.clear()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The next function gets a file name of meta data with all the apartments of a city for sale in Yad-2 and creates a dataframe from it:\n",
    "###### The function were written with chatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_df(file_name):\n",
    "    df = pd.read_csv(file_name, encoding='hebrew')\n",
    "    #finds the number of apartments at the meta data df:\n",
    "    x = 0\n",
    "    for row in range(0, df.shape[0]):\n",
    "        x += len(df.loc[row, 'sea_view'].split(','))\n",
    "    indexes = list(range(1, x+1))\n",
    "    new_df = pd.DataFrame({'index':indexes}) \n",
    "    #creates a regular df:\n",
    "    for column in df.columns:\n",
    "        l = []\n",
    "        for row in range(0, df.shape[0]):\n",
    "            l += ast.literal_eval(df.loc[row, column].strip('\\\\n'))\n",
    "        l = [i for i in l if i != '']  \n",
    "        new_df[column] = l\n",
    "    return new_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The next function calls to reorder_df() and creates files of dataframes for each city at the cities list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_df():\n",
    "    cities = ['jerusalem', 'tel-aviv', 'haifa', 'rishon-lezion', 'petah-tikva', 'netanya', 'holon', 'beer-sheva', 'ashdod','bnei-brakh']\n",
    "    for i in range(0, len(cities)):\n",
    "        src = f'C:\\\\Users\\\\Tal\\\\Desktop\\\\לימודים\\\\מדעי נתונים\\\\{cities[i]}_df_file_3_rooms.csv'\n",
    "        new_df = reorder_df(src)\n",
    "        new_df.to_csv(f'C:\\\\Users\\\\Tal\\\\Desktop\\\\לימודים\\\\מדעי נתונים\\\\apartments_info\\\\{cities[i]}_df_file_3_rooms.csv', encoding='hebrew')\n",
    "        print(cities[i])\n",
    "fix_df()    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ad-nadlan crawling:**\n",
    "##### The next function gets URL and crawl all the data about all the deals that have been maked in that city from 2010 to 2023:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deals(url):\n",
    "    data = {'city':[],'street':[],'rooms':[],'size':[],'floor':[],'date_builded':[],\n",
    "            '2010':[],'2011':[],'2012':[],'2013':[],'2014':[],'2015':[],'2016':[],\n",
    "            '2017':[], '2018':[], '2019':[], '2020':[], '2021':[], '2022':[],'2023':[]\n",
    "    }\n",
    "    df = pd.DataFrame(data)        \n",
    "    user_agent= {'User-agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers=user_agent)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    streets = []\n",
    "    flag = 1\n",
    "    while(flag):\n",
    "        vals = soup.find_all(\"td\")\n",
    "        t_df = pd.DataFrame(data)\n",
    "        row_index = 1\n",
    "        for i, street in enumerate(vals[2::9]):\n",
    "            date = vals[(i * 9 + 0)].text\n",
    "            year = date[-4:]\n",
    "            if street.text == '':\n",
    "                continue\n",
    "            else:\n",
    "                streets.append(street.text)\n",
    "                row =pd.DataFrame({\n",
    "                    'city':vals[i * 9 + 1].text,'street': vals[i * 9 + 2].text,\n",
    "                    'rooms':vals[i * 9 + 3].text,'size':vals[i * 9 + 4].text,\n",
    "                    'floor':vals[i * 9 + 5].text,'date_builded':vals[i * 9 + 8].text,\n",
    "                    '2010':'none','2011':'none','2012':'none','2013':'none','2014':'none',\n",
    "                    '2015':'none','2016':'none','2017':'none', '2018':'none', '2019':'none', \n",
    "                    '2020':'none','2021':'none', '2022':'none','2023':'none'}, index=[row_index])    \n",
    "                row[year] = vals[i * 9 + 6].text #to get the full price enter : vals[i * 9 + 6].text\n",
    "                t_df = pd.concat([row,t_df.loc[:]], ignore_index=True)\n",
    "                row_index += 1\n",
    "        df = pd.concat([df, t_df])\n",
    "        df = df.reset_index(drop=True)\n",
    "        link = soup.find_all('a',attrs={'class','page-link text-nowrap px-3 py-2 rounded-pill'}).pop()\n",
    "        if 'הבא' in link.text:\n",
    "            next_page = 'https://www.ad.co.il' + soup.find_all('a',attrs={'class','page-link text-nowrap px-3 py-2 rounded-pill'}).pop()['href']\n",
    "            response = requests.get(next_page,headers=user_agent)\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        else: flag = 0    \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The next function call to get_deals() function to crawl information about all the deals that have been maked in each city from the cities list and creates a data frame for each city.\n",
    "##### links for last deals in real estate:\n",
    "**Jerusalem**: https://www.ad.co.il/nadlanprice?rooms=3,3&city=jerusalem&year=2010,2023&area=jerusalem-maale-adummim&pageindex=1\n",
    "\n",
    "**Tel-aviv**: https://www.ad.co.il/nadlanprice?rooms=3,3&year=2010,2023&area=tel-aviv-area&city=tel-aviv&pageindex=1\n",
    "\n",
    "**Haifa**: https://www.ad.co.il/nadlanprice?rooms=3,3&year=2010,2023&area=haifa-hof-hacarmel&city=haifa&pageindex=1\n",
    "\n",
    "**Rishon-lezion**: https://www.ad.co.il/nadlanprice?rooms=3,3&year=2010,2023&area=rishon-lezion-area&city=rishon-lezion&pageindex=1\n",
    "\n",
    "**Petah-tikva**: https://www.ad.co.il/nadlanprice?rooms=3,3&year=2010,2023&area=petah-tikva-area&city=petah-tikva,givat-hashlosha&pageindex=1\n",
    "\n",
    "**Netanya**: https://www.ad.co.il/nadlanprice?rooms=3,3&year=2010,2023&city=netanya&area=netanya-area&pageindex=1\n",
    "\n",
    "**Holon**:https://www.ad.co.il/nadlanprice?rooms=3,3&year=2010,2023&city=netanya&area=netanya-area&pageindex=1\n",
    "\n",
    "**Beer-sheba**:  https://www.ad.co.il/nadlanprice?rooms=3,3&year=2010,2023&city=beersheba&area=beer-sheva-area&pageindex=1\n",
    "\n",
    "**Bnei-brakh**:https://www.ad.co.il/nadlanprice?rooms=3,3&year=2010,2023&city=bnei-brakh&area=ramat-gan-givatayim&pageindex=1\n",
    "\n",
    "**Ashdod**:https://www.ad.co.il/nadlanprice?rooms=3,3&year=2010,2023&area=ashdod-ashkelon&city=ashdod&pageindex=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deals_files():\n",
    "    urls = ['https://www.ad.co.il/nadlanprice?rooms=3,3&year=2010,2023&city=bnei-brakh&area=ramat-gan-givatayim&orderby=4'\n",
    "            'https://www.ad.co.il/nadlanprice?rooms=3,3&city=jerusalem&year=2010,2023&area=jerusalem-maale-adummim&orderby=4',\n",
    "            'https://www.ad.co.il/nadlanprice?rooms=3,3&year=2010,2023&area=tel-aviv-area&city=tel-aviv&orderby=4',\n",
    "            'https://www.ad.co.il/nadlanprice?rooms=3,3&year=2010,2023&area=haifa-hof-hacarmel&city=haifa&orderby=4',\n",
    "            'https://www.ad.co.il/nadlanprice?rooms=3,3&year=2010,2023&area=rishon-lezion-area&city=rishon-lezion&orderby=4',\n",
    "            'https://www.ad.co.il/nadlanprice?rooms=3,3&year=2010,2023&area=petah-tikva-area&city=petah-tikva,givat-hashlosha&orderby=4',\n",
    "            'https://www.ad.co.il/nadlanprice?rooms=3,3&year=2010,2023&city=netanya&area=netanya-area&orderby=4',\n",
    "            'https://www.ad.co.il/nadlanprice?rooms=3,3&year=2010,2023&city=holon&area=holon-area&orderby=4',\n",
    "            'https://www.ad.co.il/nadlanprice?rooms=3,3&year=2010,2023&city=beer-sheva&area=beer-sheva-area&orderby=4',\n",
    "            'https://www.ad.co.il/nadlanprice?rooms=3,3&year=2010,2023&area=ashdod-ashkelon&city=ashdod&orderby=4',\n",
    "        ]    \n",
    "    cities = ['jerusalem', 'tel-aviv', 'haifa', 'rishon-lezion', 'petah-tikva', 'netanya', 'holon', 'beer-sheva', 'ashdod','bnei-brakh']\n",
    "    for i, url in enumerate(urls):\n",
    "        result = get_deals(url)\n",
    "        result.drop_duplicates()\n",
    "        print(cities[i])\n",
    "        result.to_csv(f'C:\\\\Users\\\\Tal\\\\Desktop\\\\לימודים\\\\מדעי נתונים\\\\last_deals_expirience\\\\{cities[i]}_3_rooms.csv', encoding='hebrew')\n",
    "create_deals_files()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The next function summerize the data frames of the last deals by calculating the average sum for all the deals per a year for each building:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_deals_df():\n",
    "    cities = ['jerusalem', 'tel-aviv', 'haifa', 'rishon-lezion', 'petah-tikva', 'netanya', 'holon', 'beer-sheva', 'ashdod','bnei-brakh']\n",
    "    data = {'city':[],'street':[],'rooms':[],'size':[],'floor':[],'date_builded':[],\n",
    "            '2010':[],'2011':[],'2012':[],'2013':[],'2014':[],'2015':[],'2016':[],\n",
    "            '2017':[], '2018':[], '2019':[], '2020':[], '2021':[], '2022':[],'2023':[]\n",
    "    }\n",
    "    for city in cities:\n",
    "        src = f'C:\\\\Users\\\\Tal\\\\Desktop\\\\לימודים\\\\מדעי נתונים\\\\last_deals_expirience\\\\{city}_3_rooms.csv'\n",
    "        df = pd.read_csv(src, encoding='hebrew')\n",
    "        df.drop_duplicates(subset=['city', 'street', 'rooms', 'size', 'floor', 'date_builded', '2010', '2011', '2012', '2013', '2014', '2015',\n",
    "                                    '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023'], inplace=True)\n",
    "                                    \n",
    "        df = df.reset_index(drop=True)\n",
    "        new_df = pd.DataFrame(data)\n",
    "        count= [1 for _ in range(14)] \n",
    "        r = 0\n",
    "        while r < (df.shape[0]-1):\n",
    "            index = 1\n",
    "            row = [df.loc[r, 'city'], df.loc[r, 'street'], df.loc[r, 'rooms'], df.loc[r, 'size'], df.loc[r, 'floor'], df.loc[r, 'date_builded'],\n",
    "                   'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none']\n",
    "            while(0 < index < (df.shape[0])):\n",
    "                if (r + index < df.shape[0]) and df.loc[r + index, 'street'] in df.loc[r, 'street']  : \n",
    "                        for year in range(2010, 2024):\n",
    "                            s1 = str(df.loc[r, f'{year}'])\n",
    "                            s2 = str(df.loc[r + index, f'{year}'])\n",
    "                            if s1 != 'none' and s2 != 'none' :\n",
    "                                if math.isnan(float(s2.replace(\",\" , \"\"))) :\n",
    "                                    df.loc[r + index, f'{year}'] = 'none'\n",
    "                                    break\n",
    "                                elif math.isnan(float(s1.replace(\",\" , \"\"))) :\n",
    "                                    df.loc[r + index, f'{year}'] = 'none'\n",
    "                                    break\n",
    "                                else:\n",
    "                                    df.loc[r, f'{year}'] = int(s1.replace(\",\" , \"\")) + int(s2.replace(\",\" , \"\"))\n",
    "                                    count[year-2010] += 1\n",
    "                                    break\n",
    "                            elif df.loc[r + index, f'{year}'] != 'none' and  (df.loc[r, f'{year}'] == 'none' or math.isnan(float(s1.replace(\",\" , \"\"))) == True):\n",
    "                                row[year-2004] =  df.loc[r + index, f'{year}']\n",
    "                                df.loc[r, f'{year}'] = df.loc[r + index, f'{year}']\n",
    "                                break\n",
    "                        index += 1\n",
    "                else:\n",
    "                    for i, c in enumerate(count):\n",
    "                        if c > 1:\n",
    "                            row[i + 6] = int(df.loc[r, f'{i+2010}'] / c)                  \n",
    "                    count= [1 for _ in range(14)]\n",
    "                    new_df.loc[len(new_df.index)] = row\n",
    "                    r += index\n",
    "                    index = 0\n",
    "        print(city)\n",
    "        new_df.to_csv(f'C:\\\\Users\\\\Tal\\\\Desktop\\\\לימודים\\\\מדעי נתונים\\\\last_deals_expirience\\\\fixed_{city}_3_rooms.csv', encoding=\"hebrew\")\n",
    "clean_deals_df()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **creating final files**\n",
    "#### The next functions taking care the for all the data frames that we crawled and creating files from them of a one data frame per each city from the cities list."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The following function is designed to handle the addresses that appear in each data frame we built so that we can merge all the data frames together,the function remove the chars: /.'- from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_characters(strings):\n",
    "    if type(strings) == list:\n",
    "        result = []\n",
    "        for string in strings:\n",
    "            cleaned_string = string.replace('-', ' ').replace(\"'\", '').replace('/', '').replace('\"', '').replace('.', '').replace('יי', 'י').replace('וו', 'ו')\n",
    "            cleaned_string = cleaned_string.split(\" \")\n",
    "            if 'מפה' in cleaned_string:\n",
    "                cleaned_string.remove('מפה')\n",
    "            if 'שד' in cleaned_string:\n",
    "                cleaned_string.remove('שד')\n",
    "            if 'שדרות' in cleaned_string:\n",
    "                cleaned_string.remove('שדרות')\n",
    "            cleaned_string.sort(reverse=True)\n",
    "            cleaned_string = [k.strip() for k in cleaned_string]\n",
    "            string_template = ' '.join(cleaned_string)\n",
    "            result.append(string_template.strip())\n",
    "            result.sort()\n",
    "    elif type(strings) == dict:\n",
    "        result = {}\n",
    "        for key, value in strings.items():\n",
    "            cleaned_string = key.replace('-', ' ').replace(\"'\", '').replace('/', ' ').replace('\"', '').replace('.', ' ').replace('יי', 'י').replace('וו', 'ו')\n",
    "            cleaned_string = cleaned_string.split(\" \")\n",
    "            if 'מפה' in cleaned_string:\n",
    "                cleaned_string.remove('מפה')\n",
    "            if 'שד' in cleaned_string:\n",
    "                cleaned_string.remove('שד')\n",
    "            if 'שדרות' in cleaned_string:\n",
    "                cleaned_string.remove('שדרות')\n",
    "            cleaned_string.sort(reverse=True)\n",
    "            cleaned_string = [k.strip() for k in cleaned_string]\n",
    "            string_template = ' '.join(cleaned_string)\n",
    "            result[string_template.strip()] = value\n",
    "        result = dict(sorted(result.items()))\n",
    "    elif type(strings) == type(pd.DataFrame()):\n",
    "        result = strings\n",
    "        for index, street in enumerate(result['streets']):\n",
    "            cleaned_string = street.replace('-', ' ').replace(\"'\", '').replace('/', ' ').replace('\"', '').replace('.', ' ').replace('יי', 'י').replace('וו', 'ו')\n",
    "            cleaned_string = cleaned_string.split(\" \")\n",
    "            cleaned_string = [k.strip() for k in cleaned_string]\n",
    "            if 'מפה' in cleaned_string:\n",
    "                cleaned_string.remove('מפה')\n",
    "            if 'שד' in cleaned_string:\n",
    "                cleaned_string.remove('שד')\n",
    "            if 'שדרות' in cleaned_string:\n",
    "                cleaned_string.remove('שדרות')\n",
    "            cleaned_string.sort(reverse=True)\n",
    "            string_template = ' '.join(cleaned_string)\n",
    "            result.loc[index, 'streets'] = string_template.strip()    \n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The next function help us to sort the addresses and compre between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_addresses_name(streets):\n",
    "    streets_name = []\n",
    "    for address in streets:\n",
    "        parts = address.split()\n",
    "        if parts[-1].isdigit():\n",
    "            parts.pop()\n",
    "        street_name = ' '.join(parts)\n",
    "        streets_name.append(street_name)\n",
    "    return streets_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next function creates a dataframe that includes all the parameters we collected:\n",
    "1. The information about the apartment\n",
    "2. The last deals about the apartment spreated by years from 2010 to 2023\n",
    "3. If the apartment's buliding is in tma38 proccess it will get the value 1\n",
    "4. If the apartment's buliding is in tma38 type 2 proccess it will get the value 2\n",
    "5. If the apartment's buliding is in tma38 type 2 proccess it will get the value 3\n",
    "6. If the apartment's buliding is in construction_evacuation proccess it will get the value 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_columns(file_name, city, h_city):\n",
    "    df = pd.read_csv(file_name, encoding='hebrew')\n",
    "    df.drop(['Unnamed: 0', 'index'], axis=1, inplace=True)\n",
    "    df.drop_duplicates(subset=['prices', 'streets', 'cities', 'floors', 'sizes'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    #add columns to the df:\n",
    "    indexes = ['none' for _ in range(0, df.shape[0])]\n",
    "    df['construction_evacuation'] = [0 for _ in range(0, df.shape[0])]\n",
    "    for year in range(2010, 2024):\n",
    "        df[f'{year}'] = indexes\n",
    "    #sorts the addresses values in the df:\n",
    "    df = remove_characters(df)\n",
    "    df.sort_values(by='streets', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    streets = df[\"streets\"].values\n",
    "    #fill the tma38 column:\n",
    "    tma_dict = tma_df(h_city) #dynamic crawling\n",
    "    clean_tma_dict = remove_characters(tma_dict)\n",
    "    for index, address in enumerate(streets):\n",
    "        for key, value in clean_tma_dict.items():\n",
    "            if address == key:\n",
    "                df.loc[index, \"construction_evacuation\"] = value\n",
    "    #fill the construction_evacuation column:\n",
    "    ce_list = get_Construction_evacuation_complexes(h_city) #dynamic crawling\n",
    "    if len(ce_list) > 0:\n",
    "        clean_ce = remove_characters(ce_list) \n",
    "        ce_set = set(clean_ce)\n",
    "        for index, address in enumerate(streets):\n",
    "            if address in ce_set:\n",
    "                df.loc[index, \"construction_evacuation\"] = 4\n",
    "            elif address > clean_ce[-1]:\n",
    "                break\n",
    "    #fill the years columns:\n",
    "    deals_df = pd.read_csv(f\"C:\\\\Users\\\\Tal\\Desktop\\\\לימודים\\מדעי נתונים\\\\last_deals_expirience\\\\fixed_{city}_3_rooms.csv\", encoding=\"hebrew\")\n",
    "    deals_df.rename(columns={'street': 'streets'}, inplace=True)\n",
    "    deals_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    deals_df = remove_characters(deals_df)\n",
    "    deals_df.sort_values(by='streets', inplace=True)\n",
    "    deals_df.drop_duplicates(inplace=True)\n",
    "    deals_df.reset_index(drop=True, inplace=True)\n",
    "    deals_df.to_csv(f\"C:\\\\Users\\\\Tal\\Desktop\\\\לימודים\\מדעי נתונים\\\\last_deals_expirience\\\\final_file_{city}_3_rooms.csv\", encoding=\"hebrew\")\n",
    "    streets_name = []\n",
    "    count= [1 for _ in range(14)]\n",
    "    streets_name = get_addresses_name(streets)\n",
    "    deals_streets_name = get_addresses_name(deals_df['streets'].values)\n",
    "    j = 0\n",
    "    i = 0\n",
    "    k = 0\n",
    "    r = 0 #the r index helps improve the time running\n",
    "    #checkks if theres any deals in the df for the apartment and clac the average:\n",
    "    while i < df.shape[0] and j < deals_df.shape[0]:\n",
    "        if k >= deals_df.shape[0]:\n",
    "            break\n",
    "        elif streets_name[i] == deals_streets_name[j]:\n",
    "            k = r\n",
    "            while k < deals_df.shape[0]:\n",
    "                #checks if theres deals of the specific address and number address:\n",
    "                if streets[i] == deals_df.loc[k, 'streets'] and streets[i] != streets_name[i]:\n",
    "                    for year in range(2010, 2024):\n",
    "                        df.loc[i, f'{year}'] = deals_df.loc[k, f'{year}']\n",
    "                    count= [1 for _ in range(14)]\n",
    "                    i += 1\n",
    "                    break \n",
    "                #if there isnt any deals for the specific building then calculate all the street avrege deals:\n",
    "                elif streets_name[i] == deals_streets_name[k]:   \n",
    "                    for year in range(2010, 2024):\n",
    "                        s1 = str(df.loc[i, f'{year}'])\n",
    "                        s2 = str(deals_df.loc[k, f'{year}'])\n",
    "                        if s1 != 'none' and s2 != 'none' and s1 != 'nan' and s2 != 'nan':\n",
    "                                df.loc[i, f'{year}'] = int(s1.replace(\",\" , \"\")) + int(s2.replace(\",\" , \"\"))\n",
    "                                count[year-2010] += 1\n",
    "                        elif deals_df.loc[k, f'{year}'] != 'none' and  df.loc[i, f'{year}'] == 'none':\n",
    "                            df.loc[i, f'{year}'] = deals_df.loc[k, f'{year}']\n",
    "                    k += 1\n",
    "                else:\n",
    "                    for index, c in enumerate(count):\n",
    "                        if c > 1:\n",
    "                            df.loc[i, f'{index+2010}'] = int(df.loc[i, f'{index+2010}'] / c)                  \n",
    "                    count= [1 for _ in range(14)]\n",
    "                    i += 1\n",
    "                    break        \n",
    "        elif  streets_name[i] > deals_streets_name[j]:\n",
    "            if 0 < k < deals_df.shape[0]:\n",
    "                j = k\n",
    "                k = 0\n",
    "            else:\n",
    "                j += 1\n",
    "                r = j\n",
    "        else:\n",
    "            i += 1\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The next function calls to add_columns and creates a final data frame for all the cities at the cities list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_final_files():\n",
    "    #values for crawling and keys for creating files:\n",
    "    cities = {'jerusalem':'ירושלים', 'tel-aviv':'תל אביב', 'haifa':'חיפה', 'rishon-lezion':'ראשון לציון', 'petah-tikva':'פתח תקווה',\n",
    "               'netanya':'נתניה', 'holon':'חולון', 'beer-sheva':'באר שבע', 'ashdod':'אשדוד','bnei-brakh':'בני ברק'}\n",
    "                 \n",
    "    for key, value in cities.items():\n",
    "        df = add_columns(f\"C:\\\\Users\\\\Tal\\\\Desktop\\\\לימודים\\\\מדעי נתונים\\\\apartments_info\\\\{key}_df_file_3_rooms.csv\", key, value) \n",
    "        df.to_csv(f\"C:\\\\Users\\\\Tal\\\\Desktop\\\\לימודים\\\\מדעי נתונים\\\\final_df\\\\{key}_df_file_3_rooms.csv\", encoding=\"hebrew\") \n",
    "creating_final_files()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data handling**\n",
    "The next functions taking care the data in each data frame before the maching learning\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next function fills the none values of the years columns at the data frame with the price increase percentage per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_Price_increase_percentage_per_year():\n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\Tal\\\\Desktop\\\\לימודים\\\\מדעי נתונים\\\\final_df\\\\ashdod_df_file_3_rooms.csv\", encoding=\"hebrew\")\n",
    "    averages_list = []\n",
    "    \n",
    "    for year in range(2010, 2023):\n",
    "        diff_list = []\n",
    "        \n",
    "        for row in range(df.shape[0]):\n",
    "            if df.loc[row, f\"{year}\"] != 'none' and df.loc[row, f\"{year+1}\"] != 'none' and not pd.isna(df.loc[row, f\"{year}\"]) and not pd.isna(df.loc[row, f\"{year+1}\"]): \n",
    "                s1 = str(df.loc[row, f\"{year}\"])\n",
    "                s2 = str(df.loc[row, f\"{year+1}\"])\n",
    "                \n",
    "                if (float(s2.replace(\",\", \"\")) - float(s1.replace(\",\", \"\"))) != 0:\n",
    "                    diff_list.append(float(s1.replace(\",\", \"\")) / (float(s2.replace(\",\", \"\")) - float(s1.replace(\",\", \"\"))) / 100)\n",
    "        \n",
    "        if len(diff_list) > 0:\n",
    "            averages_list.append(stat.mean(diff_list))\n",
    "    \n",
    "    for year in range(2010, 2023):\n",
    "        for row in range(df.shape[0]):\n",
    "            if df.loc[row, f\"{year}\"] != 'none' and (df.loc[row, f\"{year+1}\"] == 'none' or pd.isna(df.loc[row, f\"{year+1}\"])) and not pd.isna(df.loc[row, f\"{year}\"]): \n",
    "                s1 = str(df.loc[row, f\"{year}\"])\n",
    "                try:\n",
    "                    df.loc[row, f\"{year+1}\"] = float(s1.replace(\",\", \"\")) * (1 + averages_list[year-2010])\n",
    "                except IndexError:\n",
    "                    pass\n",
    "    \n",
    "    for year in range(2022, 2010, -1):\n",
    "        for row in range(df.shape[0]):\n",
    "            if df.loc[row, f\"{year}\"] != 'none' and (df.loc[row, f\"{year-1}\"] == 'none' or pd.isna(df.loc[row, f\"{year-1}\"])) and not pd.isna(df.loc[row, f\"{year}\"]): \n",
    "                s1 = str(df.loc[row, f\"{year}\"])\n",
    "                try:\n",
    "                    df.loc[row, f\"{year-1}\"] = float(s1.replace(\",\", \"\")) / (1 + averages_list[year-2010])\n",
    "                except IndexError:\n",
    "                    pass\n",
    "    \n",
    "    df.to_csv(\"C:\\\\Users\\\\Tal\\\\Desktop\\\\לימודים\\\\מדעי נתונים\\\\Data_handling\\\\dh_ashdod_df_file_3_rooms.csv\", encoding=\"hebrew\")\n",
    "\n",
    "calc_Price_increase_percentage_per_year()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next function changes all the variabels at the data frame into numeric variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conversion_to_numeric_variables():\n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\yehud\\\\Downloads\\\\מבוא מדעי הנתונים\\\\project\\\\dh_ashdod_df_file_3_rooms.csv\", encoding=\"hebrew\")\n",
    "    for row in range(0, df.shape[0]):\n",
    "        if df.loc[row, 'terraces'] == 'none' or df.loc[row, 'terraces'] == '' or pd.isna(df.loc[row, 'terraces']):\n",
    "            df.loc[row, 'terraces'] = 0\n",
    "        else:\n",
    "            df.loc[row, 'terraces'] = int(df.loc[row, 'terraces'][-1])\n",
    "       \n",
    "        if df.loc[row, 'floors_in_building'] == 'none' or df.loc[row, 'floors_in_building'] == '' or pd.isna(df.loc[row, 'floors_in_building']):\n",
    "            df.loc[row, 'floors_in_building'] = 0\n",
    "        else:\n",
    "            df.loc[row, 'floors_in_building'] = int(df.loc[row, 'floors_in_building'][-1])\n",
    "        \n",
    "        \n",
    "        if df.loc[row, 'parkings'] == 'none' or df.loc[row, 'parkings'] == '' or pd.isna(df.loc[row, 'parkings']) or 'ללא' in df.loc[row, 'parkings']:\n",
    "            df.loc[row, 'parkings'] = 0  \n",
    "        else:\n",
    "            df.loc[row, 'parkings'] = int(df.loc[row, 'parkings'][-1])\n",
    "            \n",
    "        if df.loc[row, 'floors'] == 'none' or df.loc[row, 'floors'] == '' or pd.isna(df.loc[row, 'floors']) or 'קרקע' in df.loc[row, 'floors']:\n",
    "            df.loc[row, 'floors'] = 0  \n",
    "    \n",
    "  \n",
    "        if df.loc[row, 'status'] == 'none' or df.loc[row, 'status'] == '' or pd.isna(df.loc[row, 'status']):\n",
    "            if df.loc[row, 'renovated'] == 1:\n",
    "                df.loc[row, 'status'] = 3\n",
    "            else:\n",
    "                df.loc[row, 'status'] = 0\n",
    "        elif 'דרוש שיפוץ' in df.loc[row, 'status']:\n",
    "            df.loc[row, 'status'] = 1\n",
    "        elif 'שמור' in df.loc[row, 'status']:\n",
    "            df.loc[row, 'status'] = 2\n",
    "        elif 'משופץ' in df.loc[row, 'status']:\n",
    "            df.loc[row, 'status'] = 3\n",
    "        elif 'חדש' in df.loc[row, 'status']:\n",
    "            df.loc[row, 'status'] = 4\n",
    "       \n",
    "        \n",
    "        \n",
    "        if df.loc[row, 'time_enter'] == 'none' or df.loc[row, 'time_enter'] == '' or pd.isna(df.loc[row, 'time_enter']) or 'לא צוין' in  df.loc[row, 'time_enter'] :\n",
    "            df.loc[row, 'time_enter']=0\n",
    "        elif 'כניסה גמישה' in df.loc[row, 'time_enter'] or '202' in  df.loc[row, 'time_enter']:\n",
    "            df.loc[row, 'time_enter']=1\n",
    "        elif 'כניסה מיידית' in df.loc[row, 'time_enter']:  \n",
    "             df.loc[row, 'time_enter']=2\n",
    "    \n",
    "    df.to_csv(\"C:\\\\Users\\\\yehud\\\\Downloads\\\\מבוא מדעי הנתונים\\\\project\\\\dh_ashdod_df_file_20_rooms.csv\", encoding=\"hebrew\")\n",
    "\n",
    "\n",
    "Conversion_to_numeric_variables()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next function delete all the rows that ave no last deals or doesnt have properties about the apartment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def delete_empty_rows():\n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\yehud\\\\Downloads\\\\מבוא מדעי הנתונים\\\\project\\\\dh_ashdod_df_file_20_rooms.csv\", encoding=\"hebrew\")\n",
    "    for row in range(0,df.shape[0]):\n",
    "        if df.loc[row, '2010']== 'none':\n",
    "            df.drop(row , inplace=True)\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    df.reset_index(drop= True)\n",
    "    df.to_csv(\"C:\\\\Users\\\\yehud\\\\Downloads\\\\מבוא מדעי הנתונים\\\\project\\\\dh_ashdod_df_file_rooms.csv\", encoding=\"hebrew\")\n",
    "    \n",
    "delete_empty_rows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\yehud\\\\Downloads\\\\מבוא מדעי הנתונים\\\\project\\\\dh_ashdod_df_file_rooms.csv\", encoding=\"hebrew\") \n",
    "\n",
    "df.drop(['Unnamed: 0.3', 'Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0'], axis=1 , inplace =True)\n",
    "for row in range(0,df.shape[0]):\n",
    "    if 'צוין' in df.loc[row , 'prices'] or pd.isna(df.loc[row , 'prices']):\n",
    "        df.loc[row , 'prices']=0\n",
    "    else:\n",
    "        if '₪' in df.loc[row , 'prices'] or \"¤\" in df.loc[row , 'prices']  :\n",
    "            subset=df.loc[row , 'prices'][0:-1]\n",
    "            s1 = subset.replace(\",\",\"\")\n",
    "            print(s1)\n",
    "            df.loc[row , 'prices'] =int(s1)   \n",
    "        else:\n",
    "            s1 =str(df.loc[row , 'prices'])\n",
    "            s1 = s1.replace(\",\",\"\").strip()\n",
    "            df.loc[row , 'prices'] =int(s1)   \n",
    "sns.boxplot(df['2010'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data handling**\n",
    "The next functions taking care the data in each data frame before the maching learning\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next function fills the none values of the years columns at the data frame with the price increase percentage per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_Price_increase_percentage_per_year():\n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\yehud\\\\Desktop\\\\project 23\\\\dh_ashdod_df_file_3_rooms.csv\", encoding=\"hebrew\")\n",
    "    averages_list = []\n",
    "    \n",
    "    for year in range(2010, 2023):\n",
    "        diff_list = []\n",
    "        \n",
    "        for row in range(df.shape[0]):\n",
    "            if df.loc[row, f\"{year}\"] != 'none' and df.loc[row, f\"{year+1}\"] != 'none' and not pd.isna(df.loc[row, f\"{year}\"]) and not pd.isna(df.loc[row, f\"{year+1}\"]): \n",
    "                s1 = str(df.loc[row, f\"{year}\"])\n",
    "                s2 = str(df.loc[row, f\"{year+1}\"])\n",
    "                \n",
    "                if (float(s2.replace(\",\", \"\")) - float(s1.replace(\",\", \"\"))) != 0:\n",
    "                    diff_list.append(float(s1.replace(\",\", \"\")) / (float(s2.replace(\",\", \"\")) - float(s1.replace(\",\", \"\"))) / 100)\n",
    "        \n",
    "        if len(diff_list) > 0:\n",
    "            averages_list.append(stat.mean(diff_list))\n",
    "    \n",
    "    for year in range(2010, 2023):\n",
    "        for row in range(df.shape[0]):\n",
    "            if df.loc[row, f\"{year}\"] != 'none' and (df.loc[row, f\"{year+1}\"] == 'none' or pd.isna(df.loc[row, f\"{year+1}\"])) and not pd.isna(df.loc[row, f\"{year}\"]): \n",
    "                s1 = str(df.loc[row, f\"{year}\"])\n",
    "                try:\n",
    "                    df.loc[row, f\"{year+1}\"] = int(float(s1.replace(\",\", \"\")) * (1 + averages_list[year-2010]))\n",
    "                except IndexError:\n",
    "                    pass\n",
    "    \n",
    "    for year in range(2022, 2010, -1):\n",
    "        for row in range(df.shape[0]):\n",
    "            if df.loc[row, f\"{year}\"] != 'none' and (df.loc[row, f\"{year-1}\"] == 'none' or pd.isna(df.loc[row, f\"{year-1}\"])) and not pd.isna(df.loc[row, f\"{year}\"]): \n",
    "                s1 = str(df.loc[row, f\"{year}\"])\n",
    "                try:\n",
    "                    df.loc[row, f\"{year-1}\"] = int(float(s1.replace(\",\", \"\")) / (1 + averages_list[year-2010]))\n",
    "                except IndexError:\n",
    "                    pass\n",
    "    \n",
    "    df.to_csv(\"C:\\\\Users\\\\yehud\\\\Desktop\\\\project 23\\\\dh_ashdod_df_file_3_rooms.csv\", encoding=\"hebrew\")\n",
    "\n",
    "calc_Price_increase_percentage_per_year()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conversion_to_numeric_variables(city , hcity):\n",
    "    df = pd.read_csv(f\"C:\\\\Users\\\\yehud\\\\Desktop\\\\project 23\\\\dh_{city}_df_file_3_rooms.csv\", encoding=\"hebrew\")\n",
    "    index_neighborhood=1\n",
    "    dict_city={}\n",
    "    for row in range(0, df.shape[0]):\n",
    "        if df.loc[row, 'terraces'] == 'none' or df.loc[row, 'terraces'] == '' or pd.isna(df.loc[row, 'terraces']):\n",
    "            df.loc[row, 'terraces'] = 0\n",
    "        else:\n",
    "            df.loc[row, 'terraces'] = int(df.loc[row, 'terraces'][-1])\n",
    "       \n",
    "        if df.loc[row, 'floors_in_building'] == 'none' or df.loc[row, 'floors_in_building'] == '' or pd.isna(df.loc[row, 'floors_in_building']):\n",
    "            df.loc[row, 'floors_in_building'] = 0\n",
    "        else:\n",
    "            df.loc[row, 'floors_in_building'] = int(df.loc[row, 'floors_in_building'][-1])\n",
    "        \n",
    "        \n",
    "        if df.loc[row, 'parkings'] == 'none' or df.loc[row, 'parkings'] == '' or pd.isna(df.loc[row, 'parkings']) or 'ללא' in df.loc[row, 'parkings']:\n",
    "            df.loc[row, 'parkings'] = 0  \n",
    "        else:\n",
    "            df.loc[row, 'parkings'] = int(df.loc[row, 'parkings'][-1])\n",
    "            \n",
    "        if df.loc[row, 'floors'] == 'none' or df.loc[row, 'floors'] == '' or pd.isna(df.loc[row, 'floors']) or 'קרקע' in df.loc[row, 'floors']:\n",
    "            df.loc[row, 'floors'] = 0  \n",
    "    \n",
    "  \n",
    "        if df.loc[row, 'status'] == 'none' or df.loc[row, 'status'] == '' or pd.isna(df.loc[row, 'status']):\n",
    "            if df.loc[row, 'renovated'] == 1:\n",
    "                df.loc[row, 'status'] = 3\n",
    "            else:\n",
    "                df.loc[row, 'status'] = 0\n",
    "        elif 'דרוש שיפוץ' in df.loc[row, 'status']:\n",
    "            df.loc[row, 'status'] = 1\n",
    "        elif 'שמור' in df.loc[row, 'status']:\n",
    "            df.loc[row, 'status'] = 2\n",
    "        elif 'משופץ' in df.loc[row, 'status']:\n",
    "            df.loc[row, 'status'] = 3\n",
    "        elif 'חדש' in df.loc[row, 'status']:\n",
    "            df.loc[row, 'status'] = 4\n",
    "         \n",
    "\n",
    "        if df.loc[row, 'cities'] == 'none' or df.loc[row, 'cities'] == '' or pd.isna(df.loc[row, 'cities']):\n",
    "            df.loc[row, 'cities']=df.loc[row, 'cities'] = 0\n",
    "        else:\n",
    "            if 'דירה' in df.loc[row, 'cities']: \n",
    "                df.loc[row, 'cities']=df.loc[row, 'cities'].replace('דירה', \"\").replace(\",\",\"\")\n",
    "\n",
    "            if hcity in df.loc[row, 'cities']:\n",
    "                df.loc[row, 'cities']=df.loc[row, 'cities'].replace(hcity, \"\").replace(\",\",\"\")\n",
    "        \n",
    "        if df.loc[row, 'cities'] not in dict_city:\n",
    "            dict_city[df.loc[row, 'cities']] = index_neighborhood\n",
    "            df.loc[row, 'cities']=dict_city[df.loc[row, 'cities']]\n",
    "            index_neighborhood+=1\n",
    "        else:\n",
    "            df.loc[row, 'cities']=dict_city[df.loc[row, 'cities']]\n",
    "        \n",
    "        \n",
    "        if df.loc[row, 'time_enter'] == 'none' or df.loc[row, 'time_enter'] == '' or pd.isna(df.loc[row, 'time_enter']) or 'לא צוין' in  df.loc[row, 'time_enter'] :\n",
    "            df.loc[row, 'time_enter']=0\n",
    "        elif 'כניסה גמישה' in df.loc[row, 'time_enter'] or '202' in  df.loc[row, 'time_enter']:\n",
    "            df.loc[row, 'time_enter']=1\n",
    "        elif 'כניסה מיידית' in df.loc[row, 'time_enter']:  \n",
    "             df.loc[row, 'time_enter']=2\n",
    "    \n",
    "    df.to_csv(\"C:\\\\Users\\\\yehud\\\\Downloads\\\\מבוא מדעי הנתונים\\\\project\\\\dh_ashdod_df_file_20_rooms.csv\", encoding=\"hebrew\")\n",
    "\n",
    "\n",
    "Conversion_to_numeric_variables('ashdod', 'אשדוד')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_empty_rows():\n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\yehud\\\\Downloads\\\\מבוא מדעי הנתונים\\\\project\\\\dh_ashdod_df_file_20_rooms.csv\", encoding=\"hebrew\")\n",
    "    for row in range(0,df.shape[0]):\n",
    "        if df.loc[row, '2010']== 'none':\n",
    "            df.drop(row , inplace=True)\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    df.reset_index(drop= True)\n",
    "    df.to_csv(\"C:\\\\Users\\\\yehud\\\\Downloads\\\\מבוא מדעי הנתונים\\\\project\\\\dh_ashdod_df_file_rooms.csv\", encoding=\"hebrew\")\n",
    "    \n",
    "delete_empty_rows()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\yehud\\\\Downloads\\\\מבוא מדעי הנתונים\\\\project\\\\dh_ashdod_df_file_rooms.csv\", encoding=\"hebrew\")\n",
    "df.drop([\"Unnamed: 0\"], axis=1 , inplace =True)\n",
    "df.to_csv(\"C:\\\\Users\\\\yehud\\\\Downloads\\\\מבוא מדעי הנתונים\\\\project\\\\dh_ashdod_df_file_rooms.csv\", encoding=\"hebrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\yehud\\\\Downloads\\\\מבוא מדעי הנתונים\\\\project\\\\dh_ashdod_df_file_rooms.csv\", encoding=\"hebrew\") \n",
    "\n",
    "box_l= ['prices','sizes' , '2010','2011','2012','2013','2014','2015','2016','2017','2018','2019','2020' ]\n",
    "for row in range(0,df.shape[0]):\n",
    "    if  pd.isna(df.loc[row , 'prices']) :\n",
    "        df.loc[row , 'prices']=0\n",
    "        print(type(df.loc[row , 'prices']))\n",
    "    elif  type(df.loc[row , 'prices']) ==str and 'צוין' in df.loc[row , 'prices'] :\n",
    "        df.loc[row , 'prices']=0\n",
    "       \n",
    "            \n",
    "        \n",
    "        print(type(df.loc[row , 'prices']))\n",
    "        \n",
    "    else:\n",
    "        if '₪' in df.loc[row , 'prices'] or \"¤\" in df.loc[row , 'prices']  :\n",
    "            subset=df.loc[row , 'prices'][0:-1]\n",
    "            s1 = subset.replace(\",\",\"\")\n",
    "            df.loc[row , 'prices'] =int(s1)  \n",
    "           # print(type(df.loc[row , 'prices']))\n",
    "        else:\n",
    "            s1 =str(df.loc[row , 'prices'])\n",
    "            s1 = s1.replace(\",\",\"\").strip()\n",
    "            df.loc[row , 'prices'] =int(s1)\n",
    "            print(type(df.loc[row , 'prices']))\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "   \n",
    "           \n",
    "    for col in df.columns:\n",
    "        if col == 'streets' or col == '2021'or col == '2022' or col == '2023' :\n",
    "            continue\n",
    "        df.loc[row , col]=int(df.loc[row , col])\n",
    "for row in range(0,df.shape[0]):\n",
    "    avg_l=[]\n",
    "    for index in range(0,df.shape[0]):\n",
    "        if df.loc[row, 'cities']== df.loc[index, 'cities'] and df.loc[row, 'prices']== 0 and df.loc[index, 'prices']!= 0:##############\n",
    "            avg_l.append(df.loc[index, 'prices'])  \n",
    "    if avg_l:\n",
    "        df.loc[row, 'prices'] = statistics.mean(avg_l)       \n",
    "            \n",
    "    \n",
    "df['prices'] = df['prices'].astype(float)\n",
    "\n",
    "columns = ['prices', 'sizes', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020',\n",
    "           'cities', 'floors', 'terraces', 'floors_in_building', 'parkings', 'aircondition', 'bars',\n",
    "           'elevators', 'water_headers', 'accessibility', 'shelters', 'renovated', 'storages', 'tadiran',\n",
    "           'furnitures', 'status', 'time_enter', 'sea_view', 'sukka', 'construction_evacuation']\n",
    "col_numeric=['prices', 'sizes', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020',\n",
    "             'cities', 'floors' ]\n",
    "          \n",
    "\n",
    "df_subset = df[col_numeric].astype(float).copy()# Select the specified columns from your DataFrame\n",
    "print(df_subset.corr())\n",
    "pd.plotting.scatter_matrix(df_subset, figsize=(50, 50), diagonal='kde')\n",
    "plt.show()\n",
    "df.to_csv(\"C:\\\\Users\\\\yehud\\\\Downloads\\\\מבוא מדעי הנתונים\\\\project\\\\dh_ashdod_df_file_rooms100.csv\", encoding=\"hebrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_categorial = ['prices', 'terraces', 'floors_in_building', 'parkings', 'aircondition', 'bars',\n",
    "           'elevators', 'water_headers', 'accessibility', 'shelters', 'renovated', 'storages', 'tadiran',\n",
    "           'furnitures', 'status', 'time_enter', 'sea_view', 'sukka', 'construction_evacuation']\n",
    "df_subset = df[columns_categorial].astype(float).copy()# Select the specified columns from your DataFrame\n",
    "print(df_subset.dtypes)\n",
    "print(df_subset.corr())\n",
    "pd.plotting.scatter_matrix(df_subset, figsize=(50, 50), diagonal='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_categorial = [ 'terraces', 'floors_in_building', 'parkings',\n",
    "           'elevators', 'accessibility', 'shelters', 'storages', 'sea_view']\n",
    "for col in columns_categorial:\n",
    "    sns.violinplot(x=df[col], y=df['prices'])\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Prices')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers_with_median(df, column_name):\n",
    "    median = df[column_name].mean()\n",
    "    q1 = df[column_name].quantile(0.25)\n",
    "    q3 = df[column_name].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    df[column_name] = df[column_name].apply(lambda x: median if x < lower_bound or x > upper_bound else x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_train_and_test(X, y, test_ratio, rand_state):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=rand_state)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_name, target_column):\n",
    "    df= pd.read_csv(file_name)\n",
    "    data_list = ['prices', 'cities', 'floors', 'sizes', 'terraces', 'floors_in_building', 'parkings', 'aircondition', 'bars', 'elevators', 'water_headers', 'accessibility', 'shelters', 'renovated', 'storages', 'tadiran', 'furnitures', 'status', 'time_enter', 'sea_view', 'sukka', 'construction_evacuation', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020']\n",
    "    df_selected = df[data_list]\n",
    "    new_series= pd.Series(df_selected[target_column])\n",
    "    df_selected=df_selected.drop(target_column,axis =1)\n",
    "    return df,new_series"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Ex01_python_intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
